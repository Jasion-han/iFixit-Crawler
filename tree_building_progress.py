#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
æ ‘æ„å»ºè¿›åº¦ç®¡ç†å™¨ - ä¸ºiFixitçˆ¬è™«çš„æ–‡ä»¶æ ‘æ„å»ºé˜¶æ®µå®ç°æ–­ç‚¹ç»­çˆ¬åŠŸèƒ½
æ”¯æŒå¤§è§„æ¨¡åˆ†ç±»æ ‘æ„å»ºçš„ä¸­æ–­æ¢å¤ï¼Œé¿å…é‡å¤å·¥ä½œï¼Œæé«˜æ•ˆç‡
"""

import os
import json
import time
import hashlib
import logging
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Set, Optional, Any
from urllib.parse import urlparse


class TreeBuildingProgressManager:
    """æ ‘æ„å»ºè¿›åº¦ç®¡ç†å™¨ - å®ç°æ–­ç‚¹ç»­çˆ¬åŠŸèƒ½"""
    
    def __init__(self, target_url: str, storage_root: str = None,
                 logger: Optional[logging.Logger] = None, command_arg: str = None):
        """
        åˆå§‹åŒ–æ ‘æ„å»ºè¿›åº¦ç®¡ç†å™¨

        Args:
            target_url: ç›®æ ‡URL
            storage_root: å­˜å‚¨æ ¹ç›®å½•
            logger: æ—¥å¿—è®°å½•å™¨
            command_arg: å‘½ä»¤è¡Œå‚æ•°ï¼Œç”¨äºç”Ÿæˆæ›´å‹å¥½çš„æ–‡ä»¶å
        """
        self.command_arg = command_arg
        self.target_url = target_url
        # æ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡é…ç½®æ•°æ®ä¿å­˜è·¯å¾„ï¼Œé»˜è®¤ä¸º ifixit_data
        if storage_root is None:
            storage_root = os.getenv('IFIXIT_DATA_DIR', 'ifixit_data')
        self.storage_root = Path(storage_root)
        self.logger = logger or logging.getLogger(__name__)
        
        # ç”Ÿæˆè¿›åº¦æ–‡ä»¶è·¯å¾„
        self.progress_file = self._get_progress_file_path()
        
        # è¿›åº¦çŠ¶æ€
        self.progress_data = {
            "version": "1.0",
            "target_url": target_url,
            "start_time": None,
            "last_update": None,
            "status": "not_started",  # not_started, in_progress, completed, failed
            "tree_structure": None,
            "processed_urls": set(),
            "current_processing": None,
            "failed_urls": set(),
            "statistics": {
                "total_discovered": 0,
                "total_processed": 0,
                "total_failed": 0,
                "session_start_time": None
            }
        }
        
        # åŠ è½½ç°æœ‰è¿›åº¦
        self.load_progress()
        
    def _get_progress_file_path(self) -> Path:
        """ç”Ÿæˆè¿›åº¦æ–‡ä»¶è·¯å¾„ - åŸºäºç›®æ ‡åç§°ï¼Œä¸ä½¿ç”¨å“ˆå¸Œå€¼"""
        # ä¼˜å…ˆä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°ä½œä¸ºæ–‡ä»¶å
        if hasattr(self, 'command_arg') and self.command_arg:
            # æ¸…ç†å‘½ä»¤è¡Œå‚æ•°ï¼Œç§»é™¤URLå‰ç¼€å’Œç‰¹æ®Šå­—ç¬¦
            clean_name = self.command_arg
            if clean_name.startswith('https://www.ifixit.com/'):
                clean_name = clean_name.replace('https://www.ifixit.com/', '')
            if clean_name.startswith('Device/'):
                clean_name = clean_name.replace('Device/', '')
            if clean_name.startswith('Guide/'):
                clean_name = clean_name.replace('Guide/', '')

            # æ¸…ç†ç‰¹æ®Šå­—ç¬¦ï¼Œä¿ç•™å­—æ¯æ•°å­—å’Œä¸‹åˆ’çº¿
            clean_name = ''.join(c if c.isalnum() or c in '_-' else '_' for c in clean_name)
            clean_name = clean_name.strip('_')

            if clean_name:
                filename = f"tree_progress_{clean_name}.json"
                return self.storage_root / filename

        # ä»URLæå–å¯è¯»çš„åç§°éƒ¨åˆ†ä½œä¸ºåå¤‡æ–¹æ¡ˆ
        parsed_url = urlparse(self.target_url)
        path_parts = parsed_url.path.strip('/').split('/')

        if len(path_parts) >= 2 and path_parts[0] in ['Device', 'Guide']:
            # ä½¿ç”¨è·¯å¾„çš„æœ€åä¸€éƒ¨åˆ†ä½œä¸ºæ–‡ä»¶å
            target_name = path_parts[-1] if path_parts[-1] else path_parts[-2]
            # URLè§£ç å¹¶æ¸…ç†ç‰¹æ®Šå­—ç¬¦
            from urllib.parse import unquote
            target_name = unquote(target_name)
            clean_name = ''.join(c if c.isalnum() or c in '_-' else '_' for c in target_name)
            clean_name = clean_name.strip('_')
            filename = f"tree_progress_{clean_name}.json"
        else:
            # æœ€åçš„åå¤‡æ–¹æ¡ˆ
            filename = "tree_progress_default.json"

        return self.storage_root / filename
    
    def load_progress(self) -> bool:
        """åŠ è½½ç°æœ‰è¿›åº¦"""
        try:
            if not self.progress_file.exists():
                self.logger.info(f"è¿›åº¦æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°çš„è¿›åº¦è®°å½•: {self.progress_file}")
                return False
                
            with open(self.progress_file, 'r', encoding='utf-8') as f:
                saved_data = json.load(f)
                
            # éªŒè¯è¿›åº¦æ–‡ä»¶çš„æœ‰æ•ˆæ€§
            if saved_data.get('target_url') != self.target_url:
                self.logger.warning(f"è¿›åº¦æ–‡ä»¶ç›®æ ‡URLä¸åŒ¹é…ï¼Œåˆ›å»ºæ–°çš„è¿›åº¦è®°å½•")
                return False
                
            # æ¢å¤è¿›åº¦æ•°æ®
            self.progress_data.update(saved_data)
            
            # è½¬æ¢é›†åˆç±»å‹ï¼ˆJSONä¸æ”¯æŒsetï¼‰
            self.progress_data['processed_urls'] = set(saved_data.get('processed_urls', []))
            self.progress_data['failed_urls'] = set(saved_data.get('failed_urls', []))
            
            self.logger.info(f"æˆåŠŸåŠ è½½è¿›åº¦æ–‡ä»¶: {len(self.progress_data['processed_urls'])} ä¸ªå·²å¤„ç†URL")
            return True
            
        except Exception as e:
            self.logger.error(f"åŠ è½½è¿›åº¦æ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    def save_progress(self):
        """ä¿å­˜å½“å‰è¿›åº¦"""
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            self.progress_file.parent.mkdir(parents=True, exist_ok=True)
            
            # å‡†å¤‡ä¿å­˜æ•°æ®ï¼ˆè½¬æ¢setä¸ºlistï¼‰
            save_data = self.progress_data.copy()
            save_data['processed_urls'] = list(self.progress_data['processed_urls'])
            save_data['failed_urls'] = list(self.progress_data['failed_urls'])
            save_data['last_update'] = datetime.now(timezone.utc).isoformat()
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            with open(self.progress_file, 'w', encoding='utf-8') as f:
                json.dump(save_data, f, ensure_ascii=False, indent=2)
                
            self.logger.debug(f"è¿›åº¦å·²ä¿å­˜: {len(self.progress_data['processed_urls'])} ä¸ªå·²å¤„ç†URL")
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜è¿›åº¦æ–‡ä»¶å¤±è´¥: {e}")
    
    def start_session(self):
        """å¼€å§‹æ–°çš„æ„å»ºä¼šè¯"""
        if self.progress_data['status'] == 'not_started':
            self.progress_data['start_time'] = datetime.now(timezone.utc).isoformat()
            
        self.progress_data['status'] = 'in_progress'
        self.progress_data['statistics']['session_start_time'] = datetime.now(timezone.utc).isoformat()
        
        self.logger.info(f"å¼€å§‹æ ‘æ„å»ºä¼šè¯: {self.target_url}")
        self.save_progress()
    
    def is_url_processed(self, url: str) -> bool:
        """æ£€æŸ¥URLæ˜¯å¦å·²ç»å¤„ç†å®Œæˆ"""
        return url in self.progress_data['processed_urls']
    
    def is_url_failed(self, url: str) -> bool:
        """æ£€æŸ¥URLæ˜¯å¦å¤„ç†å¤±è´¥"""
        return url in self.progress_data['failed_urls']
    
    def mark_url_processing(self, url: str, parent_path: List[str] = None):
        """æ ‡è®°URLå¼€å§‹å¤„ç†"""
        self.progress_data['current_processing'] = {
            "url": url,
            "parent_path": parent_path or [],
            "start_time": datetime.now(timezone.utc).isoformat(),
            "children_discovered": 0,
            "children_processed": 0
        }

        self.logger.debug(f"å¼€å§‹å¤„ç†URL: {url}")

        # ä¿å­˜å½“å‰å¤„ç†çŠ¶æ€
        self.save_progress()
        
    def mark_url_completed(self, url: str, children_count: int = 0):
        """æ ‡è®°URLå¤„ç†å®Œæˆ"""
        self.progress_data['processed_urls'].add(url)
        self.progress_data['statistics']['total_processed'] += 1

        # æ¸…é™¤å½“å‰å¤„ç†çŠ¶æ€
        if (self.progress_data['current_processing'] and
            self.progress_data['current_processing']['url'] == url):
            self.progress_data['current_processing'] = None

        self.logger.debug(f"URLå¤„ç†å®Œæˆ: {url} (å­åˆ†ç±»: {children_count})")

        # ç«‹å³ä¿å­˜è¿›åº¦ï¼Œç¡®ä¿æ•°æ®ä¸ä¸¢å¤±
        self.save_progress()
    
    def mark_url_failed(self, url: str, error: str = ""):
        """æ ‡è®°URLå¤„ç†å¤±è´¥"""
        self.progress_data['failed_urls'].add(url)
        self.progress_data['statistics']['total_failed'] += 1
        
        # æ¸…é™¤å½“å‰å¤„ç†çŠ¶æ€
        if (self.progress_data['current_processing'] and 
            self.progress_data['current_processing']['url'] == url):
            self.progress_data['current_processing'] = None
            
        self.logger.warning(f"URLå¤„ç†å¤±è´¥: {url} - {error}")
        self.save_progress()
    
    def update_children_discovered(self, count: int):
        """æ›´æ–°å‘ç°çš„å­åˆ†ç±»æ•°é‡"""
        if self.progress_data['current_processing']:
            self.progress_data['current_processing']['children_discovered'] = count
            self.progress_data['statistics']['total_discovered'] += count
    
    def update_children_processed(self, count: int):
        """æ›´æ–°å·²å¤„ç†çš„å­åˆ†ç±»æ•°é‡"""
        if self.progress_data['current_processing']:
            self.progress_data['current_processing']['children_processed'] = count
    
    def save_tree_structure(self, tree_structure: Dict[str, Any]):
        """ä¿å­˜å½“å‰çš„æ ‘å½¢ç»“æ„"""
        self.progress_data['tree_structure'] = tree_structure
        self.save_progress()
    
    def get_tree_structure(self) -> Optional[Dict[str, Any]]:
        """è·å–å·²ä¿å­˜çš„æ ‘å½¢ç»“æ„"""
        return self.progress_data.get('tree_structure')
    
    def complete_session(self):
        """å®Œæˆæ„å»ºä¼šè¯"""
        self.progress_data['status'] = 'completed'
        self.progress_data['current_processing'] = None
        
        self.logger.info(f"æ ‘æ„å»ºä¼šè¯å®Œæˆ: å¤„ç†äº† {len(self.progress_data['processed_urls'])} ä¸ªURL")
        self.save_progress()
    
    def fail_session(self, error: str = ""):
        """æ ‡è®°ä¼šè¯å¤±è´¥"""
        self.progress_data['status'] = 'failed'
        self.progress_data['error'] = error
        
        self.logger.error(f"æ ‘æ„å»ºä¼šè¯å¤±è´¥: {error}")
        self.save_progress()
    
    def get_progress_stats(self) -> Dict[str, Any]:
        """è·å–è¿›åº¦ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.progress_data['statistics'].copy()
        stats.update({
            'processed_count': len(self.progress_data['processed_urls']),
            'failed_count': len(self.progress_data['failed_urls']),
            'status': self.progress_data['status'],
            'current_processing': self.progress_data['current_processing']
        })
        return stats
    
    def reset_progress(self):
        """é‡ç½®è¿›åº¦ï¼ˆå¼ºåˆ¶é‡æ–°å¼€å§‹ï¼‰"""
        self.logger.info("é‡ç½®æ ‘æ„å»ºè¿›åº¦")
        
        # å¤‡ä»½å½“å‰è¿›åº¦æ–‡ä»¶
        if self.progress_file.exists():
            backup_file = self.progress_file.with_suffix('.backup.json')
            self.progress_file.rename(backup_file)
            self.logger.info(f"å·²å¤‡ä»½ç°æœ‰è¿›åº¦æ–‡ä»¶åˆ°: {backup_file}")
        
        # é‡ç½®è¿›åº¦æ•°æ®
        self.progress_data = {
            "version": "1.0",
            "target_url": self.target_url,
            "start_time": None,
            "last_update": None,
            "status": "not_started",
            "tree_structure": None,
            "processed_urls": set(),
            "current_processing": None,
            "failed_urls": set(),
            "statistics": {
                "total_discovered": 0,
                "total_processed": 0,
                "total_failed": 0,
                "session_start_time": None
            }
        }
    
    def display_progress_report(self):
        """æ˜¾ç¤ºè¿›åº¦æŠ¥å‘Š"""
        stats = self.get_progress_stats()
        
        print("\n" + "="*60)
        print("ğŸŒ³ æ ‘æ„å»ºè¿›åº¦æŠ¥å‘Š")
        print("="*60)
        print(f"ç›®æ ‡URL: {self.target_url}")
        print(f"çŠ¶æ€: {stats['status']}")
        print(f"å·²å¤„ç†URL: {stats['processed_count']}")
        print(f"å¤±è´¥URL: {stats['failed_count']}")
        print(f"æ€»å‘ç°æ•°: {stats['total_discovered']}")
        
        if stats['current_processing']:
            current = stats['current_processing']
            print(f"å½“å‰å¤„ç†: {current['url']}")
            print(f"çˆ¶è·¯å¾„: {' > '.join(current.get('parent_path', []))}")
            print(f"å­åˆ†ç±»è¿›åº¦: {current.get('children_processed', 0)}/{current.get('children_discovered', 0)}")
        
        if stats['processed_count'] > 0 and stats['total_discovered'] > 0:
            progress_rate = (stats['processed_count'] / stats['total_discovered']) * 100
            print(f"æ•´ä½“è¿›åº¦: {progress_rate:.1f}%")
        
        print("="*60)
    
    def cleanup_progress_file(self):
        """æ¸…ç†è¿›åº¦æ–‡ä»¶ï¼ˆåœ¨æˆåŠŸå®Œæˆåè°ƒç”¨ï¼‰"""
        try:
            if self.progress_file.exists():
                self.progress_file.unlink()
                self.logger.info("å·²æ¸…ç†è¿›åº¦æ–‡ä»¶")
        except Exception as e:
            self.logger.error(f"æ¸…ç†è¿›åº¦æ–‡ä»¶å¤±è´¥: {e}")

    def get_resume_point(self) -> Optional[Dict[str, Any]]:
        """è·å–æ¢å¤ç‚¹ä¿¡æ¯"""
        if self.progress_data['status'] != 'in_progress':
            return None

        return {
            'tree_structure': self.progress_data.get('tree_structure'),
            'processed_urls': self.progress_data['processed_urls'],
            'failed_urls': self.progress_data['failed_urls'],
            'current_processing': self.progress_data.get('current_processing')
        }

    def should_skip_url(self, url: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è·³è¿‡æŸä¸ªURLçš„é‡æ–°å¤„ç†"""
        return self.is_url_processed(url) or self.is_url_failed(url)

    def should_skip_url_processing_only(self, url: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è·³è¿‡URLçš„å¤„ç†ï¼Œä½†ä»éœ€è¦éå†å…¶å­èŠ‚ç‚¹"""
        return self.is_url_processed(url)

    def get_failed_urls_for_retry(self) -> Set[str]:
        """è·å–éœ€è¦é‡è¯•çš„å¤±è´¥URL"""
        return self.progress_data['failed_urls'].copy()

    def clear_failed_url(self, url: str):
        """æ¸…é™¤å¤±è´¥URLæ ‡è®°ï¼ˆç”¨äºé‡è¯•ï¼‰"""
        self.progress_data['failed_urls'].discard(url)
        if self.progress_data['statistics']['total_failed'] > 0:
            self.progress_data['statistics']['total_failed'] -= 1


class TreeBuildingResumeHelper:
    """æ ‘æ„å»ºæ¢å¤åŠ©æ‰‹ - è¾…åŠ©æ–­ç‚¹ç»­çˆ¬çš„å®ç°"""

    def __init__(self, progress_manager: TreeBuildingProgressManager, logger: Optional[logging.Logger] = None):
        self.progress_manager = progress_manager
        self.logger = logger or logging.getLogger(__name__)

    def can_resume(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥æ¢å¤æ„å»º"""
        return (self.progress_manager.progress_data['status'] == 'in_progress' and
                len(self.progress_manager.progress_data['processed_urls']) > 0)

    def get_resume_strategy(self) -> str:
        """è·å–æ¢å¤ç­–ç•¥"""
        if not self.can_resume():
            return "fresh_start"

        processed_count = len(self.progress_manager.progress_data['processed_urls'])
        failed_count = len(self.progress_manager.progress_data['failed_urls'])

        if processed_count > 100:
            return "resume_from_checkpoint"
        elif failed_count > processed_count * 0.5:
            return "retry_failed_first"
        else:
            return "continue_normal"

    def prepare_resume_data(self) -> Dict[str, Any]:
        """å‡†å¤‡æ¢å¤æ‰€éœ€çš„æ•°æ®"""
        resume_point = self.progress_manager.get_resume_point()
        if not resume_point:
            return {}

        return {
            'visited_urls': resume_point['processed_urls'].copy(),
            'tree_structure': resume_point.get('tree_structure'),
            'failed_urls': resume_point['failed_urls'].copy(),
            'current_processing': resume_point.get('current_processing'),
            'strategy': self.get_resume_strategy()
        }

    def merge_tree_structures(self, existing_tree: Dict[str, Any], new_tree: Dict[str, Any]) -> Dict[str, Any]:
        """åˆå¹¶æ ‘å½¢ç»“æ„"""
        if not existing_tree:
            return new_tree
        if not new_tree:
            return existing_tree

        # ç®€å•çš„åˆå¹¶ç­–ç•¥ï¼šä¿ç•™ç°æœ‰ç»“æ„ï¼Œæ·»åŠ æ–°çš„å­èŠ‚ç‚¹
        merged = existing_tree.copy()

        # é€’å½’åˆå¹¶å­èŠ‚ç‚¹
        if 'children' in existing_tree and 'children' in new_tree:
            existing_children = {child['url']: child for child in existing_tree['children']}

            for new_child in new_tree['children']:
                child_url = new_child['url']
                if child_url in existing_children:
                    # é€’å½’åˆå¹¶å­èŠ‚ç‚¹
                    merged_child = self.merge_tree_structures(existing_children[child_url], new_child)
                    existing_children[child_url] = merged_child
                else:
                    # æ·»åŠ æ–°çš„å­èŠ‚ç‚¹
                    existing_children[child_url] = new_child

            merged['children'] = list(existing_children.values())

        return merged
