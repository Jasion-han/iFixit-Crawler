---
type: "always_apply"
---

使用简体中文回复。
注意：任何爬取操作都不能违反robots.txt文件里的爬取准许规则！

爬取的网站是https://www.ifixit.com/ 而不是 https://zh.ifixit.com/，并且要从https://www.ifixit.com/Device/这个根目录以树结构的形式进行爬取，不能仅在当前产品下的页面进行爬取。

基于现有代码里的逻辑，接下来我要爬取页面中更多的数据，比如我要爬取MacBook_Pro_17"_Unibody这个单品（无子类别）那么除了从根目录开始爬取的逻辑和数据之外还要再多获取一些数据：

就比如页面上的【指南】这块内容，我需要将指南这个标题下所有的子页面里的主体页面里的数据（文本，文档，视频等）也要爬取出来，并且按照结构化的数据进行保存，注意如果爬取过程中遇到了视频或文档，请记录他们的url链接地址即可。

另外在从根目录开始爬取的过程中，如果页面上有【故障排除】的标题则在他第一次出现的路径上进行保存一次就好，后面如果在子目录也遇到了则忽略该标题及里面的内容的爬取，同时处理逻辑也是按照处理指南一样的逻辑进行数据爬取。

这个项目是用来处理https://www.ifixit.com这个英文网站上的各个不同页面上的各种各样的数据，所以对于任何有关页面上的信息不要翻译成中文展示。
所有需要爬取的数据都应该从真实爬取到的页面信息中获取数据，不能捏造，假设，模拟数据。
在目标文件之外的每层目录里都不需要添加title，product_name和instruction_url字段信息.
在guides[]和troubleshooting[]数组里不需要添加name字段信息.
当用户在命令行输入指令的时候，程序应该先从根目录一层一层的遍历到指定文件URL地址再去深挖细节数据，在此之前的父级目录只需获取基本数据即可。

下载的图片要和引用他的文件夹放同一层。
对于项目中对所有产品的处理都不能有硬编码方式去处理，而是通用的方法去处理各个不同的产品爬取任务。

注意能在原有代码上去调整则去调整，非必要不要一味的增加新代码，新方法，这样会很难维护大量冗余的代码。

优先彻底排查现有实现的可能性，若必须引入新方案，需同步移除旧逻辑以避免冗余。

注意不能对特定产品硬编码，绝对不能手动添加/修改/删除数据，一切数据的变化操作必须靠执行爬取命令来完成，还有尽可能在需要调整的现有代码上去修改，不要一直去增加新的重复度高的方法和代码。

调整代码的时候要注意缩进问题，不能有缩进错乱情况发生

在iFixit故障排除内容爬取中，需要：

只收集主要内容：仅提取故障排除的核心内容部分
排除推荐区域：忽略页面底部的相关指南、推荐链接和推荐信息等辅助内容
避免商业内容：不收集任何推广性质的内容块
这样可以确保爬取的数据更加纯净，只包含真正有用的故障排除信息，而不会被页面的导航、推荐或商业内容污染。