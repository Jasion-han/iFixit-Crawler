#!/bin/bash

# è®¾ç½®é”™è¯¯å¤„ç†
set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º
set -u  # ä½¿ç”¨æœªå®šä¹‰å˜é‡æ—¶æŠ¥é”™

# é…ç½®å˜é‡
PROJECT_DIR="/root/SpiderDY"
LOG_FILE="ifixit_log.txt"
CRAWLER_LOG="crawler_output.log"
CONDA_ENV="py312"
CRAWLER_SCRIPT="auto_crawler.py"
CRAWLER_URL="https://www.ifixit.com/Guide"

# æ—¥å¿—å‡½æ•°
log_message() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

# é”™è¯¯å¤„ç†å‡½æ•°
handle_error() {
    log_message "âŒ è„šæœ¬æ‰§è¡Œå¤±è´¥: $1"
    exit 1
}

# å¼€å§‹æ‰§è¡Œ
log_message "===== å¼€å§‹æ›´æ–°éƒ¨ç½² ====="

# æ¿€æ´»condaç¯å¢ƒ
log_message "ğŸ”§ æ¿€æ´»condaç¯å¢ƒ: $CONDA_ENV"
if ! source ~/miniconda/bin/activate "$CONDA_ENV"; then
    handle_error "condaç¯å¢ƒæ¿€æ´»å¤±è´¥"
fi

# è¿›å…¥é¡¹ç›®ç›®å½•
log_message "ğŸ“ è¿›å…¥é¡¹ç›®ç›®å½•: $PROJECT_DIR"
if ! cd "$PROJECT_DIR"; then
    handle_error "æ— æ³•è¿›å…¥é¡¹ç›®ç›®å½•"
fi

# æ£€æŸ¥æ˜¯å¦æœ‰æœªæäº¤çš„æ›´æ”¹
if ! git diff --quiet || ! git diff --cached --quiet; then
    log_message "ğŸ’¾ ä¿å­˜å½“å‰ä¿®æ”¹"
    git stash push -m "Auto stash before update $(date)"
fi

# æ‹‰å–æœ€æ–°ä»£ç 
log_message "â¬‡ï¸  æ‹‰å–æœ€æ–°ä»£ç "
if ! git pull; then
    handle_error "Git pull å¤±è´¥"
fi

# æ›´æ–°ä¾èµ–ï¼ˆåªåœ¨requirements.txtæœ‰å˜åŒ–æ—¶ï¼‰
if git diff HEAD~1 HEAD --name-only | grep -q "requirements.txt"; then
    log_message "ğŸ“¦ æ›´æ–°Pythonä¾èµ–"
    if ! pip install -r requirements.txt; then
        log_message "âš ï¸  ä¾èµ–æ›´æ–°å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œ"
    fi
else
    log_message "ğŸ“¦ ä¾èµ–æ–‡ä»¶æ— å˜åŒ–ï¼Œè·³è¿‡æ›´æ–°"
fi

# æ£€æŸ¥çˆ¬è™«è„šæœ¬è¯­æ³•
log_message "ğŸ” æ£€æŸ¥çˆ¬è™«è„šæœ¬è¯­æ³•"
if ! python -m py_compile "$CRAWLER_SCRIPT"; then
    handle_error "çˆ¬è™«è„šæœ¬è¯­æ³•æ£€æŸ¥å¤±è´¥"
fi

# åœæ­¢å½“å‰è¿è¡Œçš„çˆ¬è™«
log_message "ğŸ›‘ åœæ­¢å½“å‰è¿è¡Œçš„çˆ¬è™«"
if pgrep -f "python $CRAWLER_SCRIPT" > /dev/null; then
    pkill -f "python $CRAWLER_SCRIPT"
    log_message "â³ ç­‰å¾…è¿›ç¨‹å®Œå…¨ç»ˆæ­¢..."

    # ç­‰å¾…è¿›ç¨‹ç»ˆæ­¢ï¼Œæœ€å¤šç­‰å¾…30ç§’
    for i in {1..30}; do
        if ! pgrep -f "python $CRAWLER_SCRIPT" > /dev/null; then
            log_message "âœ… çˆ¬è™«è¿›ç¨‹å·²åœæ­¢"
            break
        fi
        sleep 1
        if [ $i -eq 30 ]; then
            log_message "âš ï¸  å¼ºåˆ¶ç»ˆæ­¢çˆ¬è™«è¿›ç¨‹"
            pkill -9 -f "python $CRAWLER_SCRIPT" || true
        fi
    done
else
    log_message "â„¹ï¸  æ²¡æœ‰å‘ç°è¿è¡Œä¸­çš„çˆ¬è™«è¿›ç¨‹"
fi

# è®¾ç½®æ•°æ®ä¿å­˜è·¯å¾„ç¯å¢ƒå˜é‡
log_message "ğŸ”§ è®¾ç½®æ•°æ®ä¿å­˜è·¯å¾„: /home/data"
export IFIXIT_DATA_DIR="/home/data"

# ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨å¹¶æœ‰æ­£ç¡®æƒé™
if [ ! -d "/home/data" ]; then
    log_message "ğŸ“ åˆ›å»ºæ•°æ®ç›®å½•: /home/data"
    mkdir -p /home/data
    chmod 755 /home/data
fi

# é‡å¯çˆ¬è™«
log_message "ğŸš€ å¯åŠ¨æ–°çš„çˆ¬è™«è¿›ç¨‹"
if nohup python "$CRAWLER_SCRIPT" "$CRAWLER_URL" > "$CRAWLER_LOG" 2>&1 & then
    NEW_PID=$!
    log_message "âœ… çˆ¬è™«å¯åŠ¨æˆåŠŸï¼Œè¿›ç¨‹ID: $NEW_PID"

    # ç­‰å¾…å‡ ç§’æ£€æŸ¥è¿›ç¨‹æ˜¯å¦æ­£å¸¸å¯åŠ¨
    sleep 3
    if kill -0 "$NEW_PID" 2>/dev/null; then
        log_message "âœ… çˆ¬è™«è¿›ç¨‹è¿è¡Œæ­£å¸¸"
    else
        handle_error "çˆ¬è™«è¿›ç¨‹å¯åŠ¨åå¼‚å¸¸é€€å‡º"
    fi
else
    handle_error "çˆ¬è™«å¯åŠ¨å¤±è´¥"
fi

log_message "===== æ›´æ–°éƒ¨ç½²å®Œæˆ ====="
log_message "ğŸ“Š å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹è¿è¡ŒçŠ¶æ€:"
log_message "   tail -f $CRAWLER_LOG"
log_message "   ps aux | grep $CRAWLER_SCRIPT"